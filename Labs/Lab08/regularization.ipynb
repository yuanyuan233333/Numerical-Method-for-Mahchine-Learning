{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKvkeUvRrBtr"
   },
   "source": [
    "# Regularization of ANN weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8542,
     "status": "ok",
     "timestamp": 1670941034922,
     "user_tz": -60
    },
    "id": "Si_DpGyVWZ5I"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tORMQT4qrH9C"
   },
   "source": [
    "Load the [Auto MPG dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 1405,
     "status": "ok",
     "timestamp": 1670941036324,
     "user_tz": -60
    },
    "id": "iKmCEoGjLpkK",
    "outputId": "52c1a247-86d2-483b-927e-fc6e757830cb"
   },
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = [\n",
    "    \"MPG\",\n",
    "    \"Cylinders\",\n",
    "    \"Displacement\",\n",
    "    \"Horsepower\",\n",
    "    \"Weight\",\n",
    "    \"Acceleration\",\n",
    "    \"Model Year\",\n",
    "    \"Origin\",\n",
    "]\n",
    "data = pd.read_csv(\n",
    "    url, names=column_names, na_values=\"?\", comment=\"\\t\", sep=\" \", skipinitialspace=True\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ceh3Vv7bUXvN"
   },
   "source": [
    "Check is there are missing entries in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1670941036325,
     "user_tz": -60
    },
    "id": "DT0cq8gGUS-N",
    "outputId": "5fd70bdb-5b3c-438a-9e97-9bddf7f5acd0"
   },
   "outputs": [],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hVa1Yw4CUBk"
   },
   "source": [
    "Remove records with missing entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1670941036693,
     "user_tz": -60
    },
    "id": "mUziyL4kUVOj",
    "outputId": "ab478cd9-57a8-436f-c48d-9be8b8731d53"
   },
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8exyJVturUOy"
   },
   "source": [
    "## Data inspection\n",
    "\n",
    "Display some basic information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1670941036694,
     "user_tz": -60
    },
    "id": "apJCc1IPrTyp",
    "outputId": "64dbea6e-388c-4430-9247-68fe03313fc9"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1670941036694,
     "user_tz": -60
    },
    "id": "66g2s9v9nFLh",
    "outputId": "97f7b13d-7f1c-4500-eabe-0688f0f4d5bd"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1670941036946,
     "user_tz": -60
    },
    "id": "iXDJ4ARqnPfY",
    "outputId": "96bd4fbb-ff65-4b68-b554-d7f0d97876c0"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GN6DWxerbXy"
   },
   "source": [
    "We are interested in predicting the field `MPG`, measuring [fuel efficiency](https://en.wikipedia.org/wiki/Fuel_efficiency#:~:text=Fuel%20economy%20is%20the%20distance,a%20certain%20volume%20of%20fuel)), expressed in miles per gallon (MPG), where 1 MPG = 0.354006 km/L. Plot its distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1670941038298,
     "user_tz": -60
    },
    "id": "wPG0IsEWnWlN",
    "outputId": "90273051-cc9e-4f5a-de44-77a11687c8c9"
   },
   "outputs": [],
   "source": [
    "sns.displot(data[\"MPG\"], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqF8zt4pCxTO"
   },
   "source": [
    "Look for linear correlations among data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1670941038298,
     "user_tz": -60
    },
    "id": "tBNLx91znnpu",
    "outputId": "6862ef4f-3fa1-447f-e3e9-b322a4dc2790"
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 3085,
     "status": "ok",
     "timestamp": 1670941041378,
     "user_tz": -60
    },
    "id": "vYkJHwf_np_j",
    "outputId": "b316e527-d6fe-4a9f-a87c-e99233240ed0"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot=True, cmap=\"vlag_r\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 50728,
     "status": "ok",
     "timestamp": 1670941092100,
     "user_tz": -60
    },
    "id": "3Hk4oyCmCc15",
    "outputId": "7e204d39-de3c-4909-e08e-643f8bc1eb95"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJc_xoA3vLiv"
   },
   "source": [
    "## Data normalization\n",
    "\n",
    "Apply an affine transformation to the data, so that each feature has zero mean and unitary standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670941092101,
     "user_tz": -60
    },
    "id": "9eVFn6wkpDk7"
   },
   "outputs": [],
   "source": [
    "data_mean = data.mean()\n",
    "data_std = data.std()\n",
    "data_normalized = (data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1670941092636,
     "user_tz": -60
    },
    "id": "tfyO7bropWw7",
    "outputId": "9096877e-471b-4180-a8e8-1d40da23a5c7"
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(16, 6))\n",
    "sns.violinplot(data=data_normalized, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-Hzcd6RvrHK"
   },
   "source": [
    "## Train-validation split\n",
    "\n",
    "Shuffle the data using the [np.random.shuffle](https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html) function and split the data as follows:\n",
    "\n",
    "- put 80% in the train dataset\n",
    "- put 20% in the validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670941092637,
     "user_tz": -60
    },
    "id": "dT4j1Jb1AWWi",
    "outputId": "58367803-09a3-4bb0-e646-034b2f3f8f0c"
   },
   "outputs": [],
   "source": [
    "data_normalized_np = data_normalized.to_numpy()\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(data_normalized_np)\n",
    "\n",
    "fraction_validation = 0.2\n",
    "num_train = int(data_normalized_np.shape[0] * (1 - fraction_validation))\n",
    "x_train = data_normalized_np[:num_train, 1:]\n",
    "y_train = data_normalized_np[:num_train, :1]\n",
    "x_valid = data_normalized_np[num_train:, 1:]\n",
    "y_valid = data_normalized_np[num_train:, :1]\n",
    "\n",
    "print(\"train set size     : %d\" % x_train.shape[0])\n",
    "print(\"validation set size: %d\" % x_valid.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz8v0XDnwLqw"
   },
   "source": [
    "## ANN setup\n",
    "\n",
    "Write a function `params = initialize_params(layers_size)` that initializes the parameters, given the ANN architecture.\n",
    "Initialize biases with zero values, and weights with a [Glorot Normal](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) initialization, i.e. sampling from a Gaussian distribution with zero mean and with standard deviation\n",
    "\n",
    "$$\n",
    "\\sqrt{\\frac{2}{n + m}},\n",
    "$$\n",
    "\n",
    "where $n$ and $m$ are the number of input and output neurons of the corresponding weights matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1670942346849,
     "user_tz": -60
    },
    "id": "Sz4fSpfmzxnp"
   },
   "outputs": [],
   "source": [
    "def initialize_params(layers_size):\n",
    "    np.random.seed(0)  # for reproducibility\n",
    "    params = list()\n",
    "    for i in range(len(layers_size) - 1):\n",
    "        W = np.random.randn(layers_size[i + 1], layers_size[i]) * np.sqrt(\n",
    "            2 / (layers_size[i + 1] + layers_size[i])\n",
    "        )\n",
    "        b = np.zeros((layers_size[i + 1], 1))\n",
    "        params.append(W)\n",
    "        params.append(b)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF8tDoECD9z1"
   },
   "source": [
    "Implement a generic feedforward ANN with a function `y = ANN(x, params)`, using $ReLU$ as activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1670942351168,
     "user_tz": -60
    },
    "id": "TtwLtoDzqaM2",
    "outputId": "b177b3bb-1c10-4787-b2f2-ede74e8d2d35"
   },
   "outputs": [],
   "source": [
    "activation = jax.nn.relu\n",
    "\n",
    "\n",
    "def ANN(x, params):\n",
    "    layer = x.T\n",
    "    num_layers = int(len(params) / 2 + 1)\n",
    "    weights = params[0::2]\n",
    "    biases = params[1::2]\n",
    "    for i in range(num_layers - 1):\n",
    "        layer = weights[i] @ layer - biases[i]\n",
    "        if i < num_layers - 2:\n",
    "            layer = activation(layer)\n",
    "    return layer.T\n",
    "\n",
    "\n",
    "params = initialize_params([7, 10, 1])\n",
    "ANN(x_train[:10, :], params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmvIfrrQ0Fl_"
   },
   "source": [
    "Implement the quadratic loss (MSE) function `L = MSE(x, y, params)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1670942407933,
     "user_tz": -60
    },
    "id": "svtW7wfW0Da_",
    "outputId": "94b6d0a5-8726-42a1-f19b-e36ab5a32c4e"
   },
   "outputs": [],
   "source": [
    "def MSE(x, y, params):\n",
    "    error = ANN(x, params) - y\n",
    "    return jnp.mean(error * error)\n",
    "\n",
    "\n",
    "params = initialize_params([7, 10, 1])\n",
    "print(MSE(x_train, y_train, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naytNmfsHV_B"
   },
   "source": [
    "Implement an $l^2$ regularization term for the ANN weights:\n",
    "\n",
    "$$\n",
    "\\mathrm{MSW} = \\frac{1}{n_{weights}} \\sum_{i=1}^{n_{weights}} w_i^2\n",
    "$$\n",
    "\n",
    "and define the loss function as\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathrm{MSE} + \\beta \\, \\mathrm{MSW}\n",
    "$$\n",
    "\n",
    "where $\\beta$ is a suitable penalization parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1670942530402,
     "user_tz": -60
    },
    "id": "wVE1y4lLERez",
    "outputId": "339e6b74-1a21-49b8-e557-8deab6bc70c0"
   },
   "outputs": [],
   "source": [
    "def MSW(params):\n",
    "    # FILL HERE\n",
    "    # for each weigth matrix \n",
    "    # - update the weight sum (squared)\n",
    "    # - update the weight count\n",
    "    return \n",
    "\n",
    "\n",
    "def loss(x, y, params, penalization):\n",
    "    return # FILL HERE\n",
    "\n",
    "\n",
    "print(MSW(params))\n",
    "print(loss(x_train, y_train, params, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afi3qB3P0UFe"
   },
   "source": [
    "Run this cell: we will this callback to monitor training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1670942539383,
     "user_tz": -60
    },
    "id": "iFgDkl7dqkVy"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "class Callback:\n",
    "    def __init__(self, refresh_rate=250):\n",
    "        self.refresh_rate = refresh_rate\n",
    "        self.fig, self.axs = plt.subplots(1, figsize=(16, 8))\n",
    "        self.epoch = 0\n",
    "        self.__call__(-1)\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        if (epoch + 1) % self.refresh_rate == 0:\n",
    "            self.draw()\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            time.sleep(1e-16)\n",
    "\n",
    "    def draw(self):\n",
    "        if self.epoch > 0:\n",
    "            self.axs.clear()\n",
    "            self.axs.loglog(history_loss_train, \"b-\", label=\"loss train\")\n",
    "            self.axs.loglog(history_loss_valid, \"r-\", label=\"loss validation\")\n",
    "            self.axs.loglog(history_MSE_train, \"b--\", label=\"RMSE train\")\n",
    "            self.axs.loglog(history_MSE_valid, \"r--\", label=\"RMSE validation\")\n",
    "            self.axs.legend()\n",
    "            self.axs.set_title(\"epoch %d\" % (self.epoch + 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_iVlrCC00eKd"
   },
   "source": [
    "## Training\n",
    "\n",
    "Train an ANN with two hidden layers with 20 neurons each, using 5000 epochs of the SGD method (with minibatch size 100) with momentum ($\\alpha = 0.9$).\n",
    "Employ a linear decay of the learning rate:\n",
    "\n",
    "$$\n",
    "\\lambda_k = \\max\\left(\\lambda_{\\textnormal{min}}, \\lambda_{\\textnormal{max}} \\left(1 - \\frac{k}{K}\\right)\\right)\n",
    "$$\n",
    "\n",
    "with $\\lambda_{\\textnormal{min}} = 5e-3$, $\\lambda_{\\textnormal{max}} = 1e-1$ and decay length $K= 1000$.\n",
    "\n",
    "During training, store both the MSE error and the loss function obtained on the train and validation sets in 4 lists, respectively called:\n",
    "\n",
    "- `history_loss_train`\n",
    "- `history_loss_valid`\n",
    "- `history_MSE_train`\n",
    "- `history_MSE_valid`\n",
    "\n",
    "Test different choices of the penalization parameter $\\beta$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13061,
     "status": "ok",
     "timestamp": 1670942880553,
     "user_tz": -60
    },
    "id": "GYcMlwxltMt6",
    "outputId": "c65f0115-d6a9-4e4d-e414-d2bcb91fac4f"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "layers_size = [7, 20, 20, 1]\n",
    "penalization = 2.0\n",
    "# Training options\n",
    "num_epochs = 5000\n",
    "learning_rate_max = 1e-1\n",
    "learning_rate_min = 5e-3\n",
    "learning_rate_decay = 1000\n",
    "batch_size = 100\n",
    "alpha = 0.9\n",
    "########################################\n",
    "\n",
    "params = initialize_params(layers_size)\n",
    "\n",
    "grad = jax.grad(loss, argnums=2)\n",
    "MSE_jit = jax.jit(MSE)\n",
    "loss_jit = jax.jit(loss)\n",
    "grad_jit = jax.jit(grad)\n",
    "\n",
    "n_samples = x_train.shape[0]\n",
    "\n",
    "history_loss_train = list()\n",
    "history_loss_valid = list()\n",
    "history_MSE_train = list()\n",
    "history_MSE_valid = list()\n",
    "\n",
    "\n",
    "def dump():\n",
    "    history_loss_train.append(loss_jit(x_train, y_train, params, penalization))\n",
    "    history_loss_valid.append(loss_jit(x_valid, y_valid, params, penalization))\n",
    "    history_MSE_train.append(MSE_jit(x_train, y_train, params))\n",
    "    history_MSE_valid.append(MSE_jit(x_valid, y_valid, params))\n",
    "\n",
    "\n",
    "dump()\n",
    "cb = Callback(refresh_rate=500)\n",
    "\n",
    "velocity = [0.0 for i in range(len(params))]\n",
    "for epoch in range(num_epochs):\n",
    "    learning_rate = max(\n",
    "        learning_rate_min, learning_rate_max * (1 - epoch / learning_rate_decay)\n",
    "    )\n",
    "    idxs = np.random.choice(n_samples, batch_size)\n",
    "    grads = grad_jit(x_train[idxs, :], y_train[idxs, :], params, penalization)\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        velocity[i] = alpha * velocity[i] - learning_rate * grads[i]\n",
    "        params[i] += velocity[i]\n",
    "\n",
    "    dump()\n",
    "    cb(epoch)\n",
    "cb.draw()\n",
    "\n",
    "print(\"loss (train     ): %1.3e\" % history_loss_train[-1])\n",
    "print(\"loss (validation): %1.3e\" % history_loss_valid[-1])\n",
    "print(\"MSE  (train     ): %1.3e\" % history_MSE_train[-1])\n",
    "print(\"MSE  (validation): %1.3e\" % history_MSE_valid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtM6IQsxJomr"
   },
   "source": [
    "We now want to to investigate more in depth the effect of the penalization parameter $\\beta$.\n",
    "Write a function that, given the penalization parameter, trains the ANN (with the same setting used above) and returns a dictionary containing the final values of:\n",
    "\n",
    "- train MSE\n",
    "- validation MSE\n",
    "- MSW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1670942958835,
     "user_tz": -60
    },
    "id": "QTGrkHNOQZEC"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "layers_size = [7, 20, 20, 1]\n",
    "# Training options\n",
    "num_epochs = 5000\n",
    "learning_rate_max = 1e-1\n",
    "learning_rate_min = 5e-3\n",
    "learning_rate_decay = 1000\n",
    "batch_size = 100\n",
    "alpha = 0.9\n",
    "\n",
    "\n",
    "def train(penalization):\n",
    "    #FILL HERE\n",
    "    return {\n",
    "        \"MSE_train\": #FILL HERE,\n",
    "        \"MSE_valid\": #FILL HERE,\n",
    "        \"MSW\": #FILL HERE,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8rOapXpKT_Y"
   },
   "source": [
    "Using the above defined function, store the obtained results for $\\beta = 0, 0.25, 0.5, 0.75, \\dots, 2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13388,
     "status": "ok",
     "timestamp": 1670942979142,
     "user_tz": -60
    },
    "id": "XDJLDB1RKSmc",
    "outputId": "dc30be58-20d4-43f9-f7c8-d7a3f2087eeb"
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"MSE_train\": list(),\n",
    "    \"MSE_valid\": list(),\n",
    "    \"MSW\": list(),\n",
    "}\n",
    "\n",
    "pen_values = np.arange(0, 2.1, 0.5)\n",
    "# FILL HERE: check how the the metric vary depending on pen_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O29cV3oKim4"
   },
   "source": [
    "Plot the trend of the five quantities as functions of $\\beta$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1670942988033,
     "user_tz": -60
    },
    "id": "9U-hxoeWR6L7",
    "outputId": "8a626b87-4647-43ae-87fa-3914ef227774"
   },
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "axs[0].plot(pen_values, results[\"MSE_train\"], \"o-\")\n",
    "axs[1].plot(pen_values, results[\"MSE_valid\"], \"o-\")\n",
    "axs[2].plot(pen_values, results[\"MSW\"], \"o-\")\n",
    "\n",
    "axs[0].set_title(\"MSE_train\")\n",
    "axs[1].set_title(\"MSE_valid\")\n",
    "axs[2].set_title(\"MSW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HtJD2jsKq0Y"
   },
   "source": [
    "Plot the _Tikhonov L-curve_, which is - in this context - the curve \"train MSE\" versus \"MSW\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1670943052211,
     "user_tz": -60
    },
    "id": "i2-QQEFYWTP4",
    "outputId": "9eb31ad7-899a-4dd0-ca48-8c026d300ced"
   },
   "outputs": [],
   "source": [
    "plt.plot(results[\"MSW\"], results[\"MSE_train\"], \"o-\")\n",
    "plt.xlabel(\"MSW\")\n",
    "plt.ylabel(\"MSE_train\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+VSCvCLE3QGfHcBq1evhU",
   "mount_file_id": "1jPUgULFGwoy5C8YoJgAzpAJgjvsLC5RD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
