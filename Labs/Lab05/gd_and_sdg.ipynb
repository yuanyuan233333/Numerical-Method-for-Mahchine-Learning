{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with JAX: Gradient Descent and Backtracking\n",
    "\n",
    "## Laboratory Session\n",
    "\n",
    "In this laboratory session, we will explore optimization techniques implemented with **JAX**.\n",
    "We will cover several optimization algorithms:\n",
    "\n",
    "- Gradient Descent (GD)\n",
    "- Gradient Descent with Backtracking Line Search\n",
    "- Exact Line Search for Quadratic Functions\n",
    "\n",
    "We will apply these methods on various benchmark functions:\n",
    "\n",
    "- Rastrigin Function\n",
    "- Ackley Function\n",
    "- Quadratic Function\n",
    "\n",
    "Let's begin by importing the rebuired packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Plotting\n",
    "\n",
    "We define a helper function `plot_optimization_2d` to visualize optimization trajectories on a 2D contour plot. This function will:\n",
    "\n",
    "- Plot the optimization path taken by Gradient Descent (GD)\n",
    "- Plot the optimization path with Backtracking Line Search if available\n",
    "- Show the function's value as a contour plot in the background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_2d(func, gd_path, gd_backtrack_path, title):\n",
    "    x_vals = jnp.linspace(-5, 5, 50)\n",
    "    y_vals = jnp.linspace(-5, 5, 50)\n",
    "    X, Y = jnp.meshgrid(x_vals, y_vals)\n",
    "    Z = jnp.array([[func(jnp.array([x, y])) for x in x_vals] for y in y_vals])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    cs = axs[0].contourf(X, Y, Z, levels=50, cmap=\"viridis\")\n",
    "    plt.colorbar(cs)\n",
    "    axs[0].contour(X, Y, Z, colors=\"white\")\n",
    "\n",
    "    gd_path = jnp.array(gd_path)\n",
    "\n",
    "    axs[0].plot(gd_path[:, 0], gd_path[:, 1], \"r.-\", label=\"GD\")\n",
    "\n",
    "    if gd_backtrack_path != []:\n",
    "        gd_backtrack_path = jnp.array(gd_backtrack_path)\n",
    "        axs[0].plot(\n",
    "            gd_backtrack_path[:, 0],\n",
    "            gd_backtrack_path[:, 1],\n",
    "            \".-\",\n",
    "            color=\"orange\",\n",
    "            label=\"GD + backtracking\",\n",
    "        )\n",
    "    axs[0].set_title(title)\n",
    "    axs[0].set_xlabel(\"x\")\n",
    "    axs[0].set_ylabel(\"y\")\n",
    "    axs[0].set_ylim([-5, 5])\n",
    "    axs[0].set_xlim([-5, 5])\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].semilogy([func(x) for x in gd_path], \"ro-\", label=\"GD\")\n",
    "    axs[1].semilogy(\n",
    "        [func(x) for x in gd_backtrack_path],\n",
    "        \"o-\",\n",
    "        color=\"orange\",\n",
    "        label=\"GD + backtracking\",\n",
    "    )\n",
    "    axs[1].legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Benchmark Functions\n",
    "\n",
    "### 1. Rastrigin Function\n",
    "\n",
    "The Rastrigin function is a **non-convex** and **multi-modal** function often used as a test for optimization algorithms.\n",
    "It is defined as:\n",
    "\n",
    "$$\n",
    "f(x) = 10 n + \\sum_{i=1}^n \\left( x_i^2 - 10 \\cos(2 \\pi x_i) \\right)\n",
    "$$\n",
    "\n",
    "with multiple local minima.\n",
    "\n",
    "### 2. Ackley Function\n",
    "\n",
    "The Ackley function is another **non-convex** function commonly used in optimization, given by:\n",
    "\n",
    "$$\n",
    "f(x) = -20 \\exp \\left( -0.2 \\sqrt{\\frac{1}{n} \\sum_{i=1}^n x_i^2} \\right) - \\exp \\left( \\frac{1}{n} \\sum_{i=1}^n \\cos(2 \\pi x_i) \\right) + 20 + e\n",
    "$$\n",
    "\n",
    "### 3. Quadratic Function\n",
    "\n",
    "The Quadratic function is **convex** and is defined as:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{2} x^T A x + b^T x + c\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the benchmark functions\n",
    "\n",
    "\n",
    "# 1. Rastrigin function\n",
    "@jax.jit\n",
    "def rastrigin(x):\n",
    "    return 10 * x.size + jnp.sum(x**2 - 10 * jnp.cos(2 * jnp.pi * x)) + 1e-10\n",
    "\n",
    "\n",
    "# 2. Ackley function\n",
    "@jax.jit\n",
    "def ackley(x):\n",
    "    a = 20\n",
    "    b = 0.2\n",
    "    c = 2 * jnp.pi\n",
    "    sum1 = jnp.sum(x**2)\n",
    "    sum2 = jnp.sum(jnp.cos(c * x))\n",
    "    return (\n",
    "        -a * jnp.exp(-b * jnp.sqrt(sum1 / x.size))\n",
    "        - jnp.exp(sum2 / x.size)\n",
    "        + a\n",
    "        + jnp.exp(1)\n",
    "    )\n",
    "\n",
    "\n",
    "# 3. Quadratic function\n",
    "quadratic_A = jnp.array([[3.0, 0.5], [0.5, 1.0]])\n",
    "quadratic_b = jnp.array([-1.0, 2.0])\n",
    "quadratic_c = jnp.dot(quadratic_b, jnp.linalg.solve(quadratic_A, quadratic_b)) / 2\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def quadratic(x):\n",
    "    return (\n",
    "        0.5 * jnp.dot(x.T, jnp.dot(quadratic_A, x))\n",
    "        + jnp.dot(quadratic_b, x)\n",
    "        + quadratic_c\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Algorithms\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "Gradient Descent is an iterative optimization algorithm defined by:\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\eta \\nabla f(x_k)\n",
    "$$\n",
    "\n",
    "where $ \\eta $ is the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(grad_func, x0, lr=0.01, tol=1e-6, max_iter=1000):\n",
    "    x = x0\n",
    "    path = [x] # for visualization purposes only\n",
    "    for _ in range(max_iter):\n",
    "        # FILL HERE:\n",
    "        # 1. gradient iteration\n",
    "        # 2. save path by appending current iteration\n",
    "        # 3. break condition\n",
    "    return x, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Backtracking Line Search\n",
    "\n",
    "Backtracking line search modifies the learning rate $ \\eta $ to ensure sufficient decrease.\n",
    "\n",
    "The key idea is to start with an initial step size and iteratively reduce it until a sufficient decrease condition is met. Specifically, the backtracking process adjusts the step size tt based on the Armijo condition:\n",
    "\n",
    "$$\n",
    "f(x - t \\nabla f(x)) \\leq f(x) - \\alpha t \\|\\nabla f(x)\\|^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ f(x) $ is the objective function,\n",
    "- $ \\nabla f(x) $ is the gradient of $ f $ at $ x $,\n",
    "- $ t $ is the step size (or learning rate) that we are adapting,\n",
    "- $ \\alpha \\in (0, 0.5) $ is a parameter controlling the required decrease,\n",
    "- $ \\|\\nabla f(x)\\|^2 $ represents the squared norm of the gradient, quantifying how steep the descent is at $ x $.\n",
    "\n",
    "The algorithm typically starts with an initial step size $ t = 1 $ and iteratively reduces it by multiplying it with a factor $ \\beta \\in (0, 1) $ (often $ \\beta = 0.8 $), until the sufficient decrease condition is satisfied. The process can be summarized as follows:\n",
    "\n",
    "1. **Initialize** $ t = 1 $.\n",
    "2. **While** $ f(x - t \\nabla f(x)) > f(x) - \\alpha t \\|\\nabla f(x)\\|^2 $:\n",
    "   - Update $ t = \\beta t $.\n",
    "3. **Return** the adjusted step size $ t $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_backtracking(func, grad_func, x0, alpha=0.3, beta=0.8, tol=1e-6, max_iter=100):\n",
    "    x = x0\n",
    "    path = [x]\n",
    "    for _ in range(max_iter):\n",
    "        # FILL HERE:\n",
    "        # 1. gradient iteration\n",
    "        #  1.1 initialize t = 1\n",
    "        #  1.2 while condition\n",
    "        #  1.3 update t\n",
    "        # 2. save path by appending current iteration\n",
    "        # 3. break condition\n",
    "    return x, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Line Search for Quadratic Function\n",
    "\n",
    "Exact line search minimizes the quadratic function\n",
    "$$f(\\boldsymbol x) = \\frac{1}{2} \\boldsymbol x^T A \\boldsymbol x + \\boldsymbol b^T \\boldsymbol x + c $$\n",
    "in each iteration by solving for the optimal step size $ t^* $ as:\n",
    "\n",
    "$$\n",
    "t^* = \\frac{\\nabla f(\\boldsymbol x)^T \\nabla f(\\boldsymbol x)}{\\nabla f(\\boldsymbol x)^T A \\nabla f(\\boldsymbol x)}\n",
    "$$\n",
    "\n",
    "Indeed, at iteration $k$, we want to minimize the (univariate) function $g$\n",
    "\n",
    "\\begin{align*}\n",
    "g(t) = f\\big(\\boldsymbol x^k + t \\boldsymbol s^{k}\\big) = \\frac12 \\big(\\boldsymbol x^k + t \\boldsymbol s^{k}\\big)^T A \\big(\\boldsymbol x^k + t \\boldsymbol s^{k}\\big) + \\boldsymbol b^T \\big(\\boldsymbol x^k + t \\boldsymbol s^{k}\\big) + c\\\\\n",
    "= \\frac12 \\big(\\boldsymbol x^k\\big)^T A \\boldsymbol x^k + \\frac12 t ^2 \\big(\\boldsymbol s^{k}\\big)^T A \\boldsymbol s^{k} + t \\big( \\boldsymbol s^k \\big)^T A \\boldsymbol x^{k} + \\boldsymbol b^T \\boldsymbol x^k + t \\boldsymbol b^T \\boldsymbol s^{k} + c \\\\\n",
    "= f\\big(\\boldsymbol x^k \\big) + \\frac12 t ^2 \\big(\\boldsymbol s^{k}\\big)^T A \\boldsymbol s^{k}+ t \\big( \\boldsymbol s^k \\big)^T A \\boldsymbol x^{k} + t \\big( \\boldsymbol s^{k}\\big)^T \\boldsymbol b\\\\\n",
    "= f\\big(\\boldsymbol x^k \\big) + \\frac12 t ^2 \\big(\\boldsymbol s^{k}\\big)^T A \\boldsymbol s^{k}+ t \\big( \\boldsymbol s^k \\big)^T \\Big[A \\boldsymbol x^{k} + \\boldsymbol b\\Big]\n",
    "\\end{align*}\n",
    "\n",
    "where $\\boldsymbol s^k = -\\nabla f(\\boldsymbol x^k)$. Performing the derivative, we have\n",
    "\n",
    "$$g'(t) = t \\big(\\boldsymbol s^{k}\\big)^T A \\boldsymbol s^{k} + \\big( \\boldsymbol s^k  \\big)^T \\Big[A \\boldsymbol x^{k} + \\boldsymbol b\\Big]$$\n",
    "\n",
    "But, by definition of $f$\n",
    "\n",
    "$$\\nabla f(\\boldsymbol x^k) = A \\boldsymbol x^k + \\boldsymbol b$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$g'(t) = t \\big(\\boldsymbol s^{k}\\big)^T A \\boldsymbol s^{k} + \\big( \\boldsymbol s^k  \\big)^T \\nabla f(\\boldsymbol x^k)$$\n",
    "\n",
    "By setting $g'(t^*) = 0$ we have\n",
    "\n",
    "$$t^* = \\frac{\\nabla f(\\boldsymbol x^k)^T \\nabla f(\\boldsymbol x^k)}{\\nabla f(\\boldsymbol x^k)^T A \\nabla f(\\boldsymbol x^k)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_line_search_quadratic(A, b, x0, tol=1e-6, max_iter=100):\n",
    "    x = x0\n",
    "    path = [x]\n",
    "    for _ in range(max_iter):\n",
    "        # FILL HERE:\n",
    "        # 1. gradient iteration (compute t*)\n",
    "        # 2. save path by appending current iteration\n",
    "        # 3. break condition\n",
    "    return x, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Optimization Algorithms\n",
    "\n",
    "Let's test our gradient descent methods on the benchmark functions, and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = jnp.array([4.0, 4.0])\n",
    "\n",
    "test_functions = [\n",
    "    (rastrigin, \"Rastrigin\"),\n",
    "    (ackley, \"Ackley\"),\n",
    "    (quadratic, \"Quadratic\"),\n",
    "]\n",
    "\n",
    "for func, name in test_functions:\n",
    "    grad_func = jax.jit(jax.grad(func))\n",
    "    print(f\"Testing on {name} function\")\n",
    "\n",
    "    # FILL HERE\n",
    "    # 1. Run Vanilla Gradient Descent\n",
    "    # 2. Run Gradient descent with backtracking\n",
    "    # 3. Plot using `plot_optimization_2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Line Search on Quadratic Function\n",
    "\n",
    "Using exact line search, we aim to find the optimal path for the **Quadratic function**. This method is specific to quadratic functions and will only be applied to this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using Stochastic Gradient Descent (SDG)\n",
    "\n",
    "In this laboratory session, we will implement a simple linear regression model using stochastic gradient descent (SGD) to minimize the mean squared error (MSE). The dataset is synthetic, and we will use JAX for efficient computation and automatic differentiation.\n",
    "\n",
    "### Problem Setup\n",
    "\n",
    "Given a set of data points $ (x_i, y_i) $, the goal is to learn the parameters $ \\theta_0 $ and $ \\theta_1 $ such that the model predicts $ y = \\theta_0 + \\theta_1 x $. We will optimize these parameters using SGD to minimize the MSE loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Data\n",
    "\n",
    "We will generate synthetic data where $ y = 1.5 x + 3 $, with some added Gaussian noise. This data will be used to test our linear regression model.\n",
    "\n",
    "Let us now generate the synthetic dataset using JAX's random number generation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "\n",
    "The linear regression model is defined as:\n",
    "\n",
    "$$ y = \\theta_0 + \\theta_1 x $$\n",
    "\n",
    "Where $ \\theta_0 $ is the intercept and $ \\theta_1 $ is the slope. We will define this model and a loss function to optimize it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE: Define the linear regression model as a jit function\n",
    "def model(theta, x):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) Loss Function\n",
    "\n",
    "The loss function we will use is the Mean Squared Error (MSE) between the predicted values and the true values:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "We will also use JAX's `jit` decorator to optimize this function for faster computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6892f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE: Mean Squared Error loss function as a jit function that uses the model\n",
    "def mse_loss(theta, x, y):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of the Loss Function\n",
    "\n",
    "We can compute the gradient of the MSE loss function with respect to the parameters $ \\theta_0 $ and $ \\theta_1 $ using JAX's automatic differentiation. This will allow us to update the parameters using gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94816db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE: Compute the gradient of the MSE loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD) Update Step\n",
    "\n",
    "In Stochastic Gradient Descent (SGD), we update the parameters using the gradient computed on a random mini-batch of the data. This allows for faster convergence compared to using the full dataset at each iteration.\n",
    "\n",
    "We will define a function to perform a single update step of SGD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent (GD) update step (jit it!)\n",
    "def sgd_update(theta, x_batch, y_batch, learning_rate):\n",
    "    # FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent with Mini-batches\n",
    "\n",
    "We will implement the full Stochastic Gradient Descent (SGD) algorithm, processing the data in mini-batches. At each epoch, we shuffle the data and update the parameters using the mini-batch gradients.\n",
    "\n",
    "Let's now define the `stochastic_gradient_descent` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent with mini-batches\n",
    "def stochastic_gradient_descent(\n",
    "    theta,\n",
    "    training_input,\n",
    "    training_labels,\n",
    "    validation_input,\n",
    "    validation_labels,\n",
    "    learning_rate=0.01,\n",
    "    epochs=100,\n",
    "    batch_size=10,\n",
    "    state=0,\n",
    "):\n",
    "    key = jax.random.PRNGKey(state)\n",
    "    for epoch in range(epochs):\n",
    "        # 1. Produce an array with permutations of the data (update the key)\n",
    "        for i in range(0, len(training_input), batch_size):\n",
    "            # 2. Get the minibatch data from the indexes of the permutation\n",
    "            # 3. Perform SGD update\n",
    "        # Print the loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            # 4. Compute the loss on the validation dataset\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Parameters\n",
    "\n",
    "After running the optimization, we will obtain the optimized values of $ \\theta_0 $ and $ \\theta_1 $. These parameters define the best-fit line for the data.\n",
    "\n",
    "Let's print the optimized parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "# Initial guess for theta_0 (intercept) and theta_1 (slope)\n",
    "theta = jnp.array([0.0, 0.0])\n",
    "\n",
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Results\n",
    "\n",
    "Finally, we can plot the original data points and the regression line defined by the optimized parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
